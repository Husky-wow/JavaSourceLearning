处理器、高速缓存、主存之间的关系（画图）。

缓存一致性问题。

解决缓存一致性问题，使用锁：
总线锁：
顾名思义，总线锁就是用来锁住总线的，我们可以通过上图来了解总线在这个场景中所处的位置。当一个CPU核执行一个线程去访问数据做操作的时候，
它会向总线上发送一个LOCK信号，此时其他的线程想要去请求主内存中的同一个共享变量的时候，就会被阻塞，这样该处理器核心就可以独享这个共享
内存。可以理解为，总线锁通过把内存和CPU之间的通信锁住，把并行化的操作变成了串行，这会导致很严重的性能问题，这与我们需要多核多线程并行
操作来提高程序的效率的目的大相径庭。所以，随着技术的发展，就出现了缓存锁。

缓存锁：
简单的说，如果某个内存区域数据，已经同时被一个以上的处理器核缓存，缓存锁就会通过缓存一致性机制来保证共享数据的可见性，当其他处理器核
回写已经被锁定的缓存行的数据时会导致该缓存行无效。就是说当某块CPU核对缓存中的数据进行操作了之后，就通知其他CPU放弃储存在它们内部的缓
存，进而从主内存中重新读取。


处理器上有一套完整的协议，来保证缓存的一致性，比较经典的应该就是MESI协议了，其实现方法是在CPU缓存中保存一个标记位，以此来标记四种状态。
另外，每个Core的Cache控制器不仅知道自己的读写操作，也监听其它Cache的读写操作，就是嗅探（snooping）协议（我个人猜测这个所谓的嗅探
机制应该是类似于观察者模式的设计）。

M：被修改的。处于这一状态的数据，只在本CPU核中有缓存数据，而其他核中没有。同时其状态相对于内存中的值来说，是已经被修改的，只是没有更新到内存中。
E：独占的。处于这一状态的数据，只有在本CPU中有缓存，且其数据没有修改，即与内存中一致。
S：共享的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致。
I：无效的。本CPU中的这份缓存已经无效。

CPU的读取会遵循几个原则（其实就是上面说的嗅探）
一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在读取操作执行之前把M其缓存行中的数据写回CPU。
（按我个人通俗一点说理解就是，我把内存中这个拼图玩具（数据）复制一份拿来玩，但是我要时刻注意有没有人要玩这个玩具，如果有人要玩，那我就要告诉他，这拼图已经被我拼成这样子了，你从这个进度开始拼吧。）

一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。

一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。

当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，如其他CPU也有该数据的缓存且状态是M，
则需要等待其把缓存更新到内存之后，再读取。当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下
性能开销是相对较大的。在写入完成后，修改其缓存状态为M。所以如果一个变量在某段时间只被一个线程频繁地修改，那么使用其内部缓存就完全可以了，并不需要涉及到总线事务。如果内存一会被这个CPU独占，一会被那个CPU
独占，这时才会不断产生RFO指令影响到并发性能。这其实是跟CPU协调机制有关，如果在CPU间调度不合理，会形成RFO指令的开销比任务开销还要大，喧宾夺主，我们反而不能提高效率。顺带一句题外话，之前听过一句话，程序玩
到最后都是性能和安全的博弈，深以为然，身为一个选择困难的人啊，很伤。

====================================================================================================================================================================================
JMM：java内存模型

JMM原子操作：
read：从主内存读取数据
load：将主内存读取到的数据写入工作内存
use：从工作内存读取数据来计算
assgin：将计算好的值重新赋值到工作内存中
store：把工作内存中变量的值同步回主内存，以便随后的write操作使用
write：将store到主内存的变量值，赋值给主内存中的变量
lock：将主内存变量加锁，标识为线程独占状态
unlock：将主内存变量解锁，解锁后其他线程可以锁定该变量

volatile缓存可见性实现原理
底层实现主要是通过汇编lock前缀指令，它会锁定这块内存区域的缓存并回写到主内存，此操作被称为“缓存锁定”

Java程序汇编代码查看（记得将hsdis解压到jre/bin目录下，并且将该jre环境指定为当前idea项目的运行环境）
-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*App.f1


并发编程三大特性：
可见性
原子性
有序性

volatile只保证
    可见性
    有序性
synchronized保证
    可见性
    有序性
    原子性

有序性：Java内存模型的有序性在上面讲解volatile时也详细地讨论过了，Java程序中天然的有序性可以总结为一句话：
如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“
线程内表现为串行的语义“（Within-Thread As-If-Serial Semantics），后半句是指”指令重排序“现象和”工作
内存与主内存同步延迟“现象。

特别关键的点：
volatile之所以不保证原子性，是因为volatile修饰的变量在不同的线程的工作内存中也存在不一致的情况。并不是任何一个线程修改了volatile变量，其他线程就能立刻感知
只有其他线程要从工作内存中使用变量的那一刻，才会发现工作内存的状态是I(invalid)，才会去主存中获取变量的值。
比如：
线程1                                         线程2
读取i=1                                       读取i=1
i++; // i=2                                   i++;    // i=2
此时没有刷新工作内存(因为此时没有涉及到读取)         存储i=2到主存
存储2到主存

所以，关于volatile才有了以下的使用准则
1. 运算结果并不依赖于变量当前的值，或者能够确保只有单一的线程修改变量的值，而其他的线程只是读取变量的值。
2. 变量不需要与其他的状态变量共同参与不变约束。

补充：JMM内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许虚拟机选择把这些操作实现为
具有原子性的操作，而且还是“强烈建议”虚拟机这样实现。在实际开发中，目前各种平台下的商用虚拟机几乎都选择把64位
数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile


先行发生原则（happen-before原则，针对的就是指令重排的机制）

如果Java内存模型中，线程之间的所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将会变得很烦琐，但是我们
在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个“先行发生（happens-before）”的原则，这个
原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发
环境下两个操作之间是否可能存在冲突的所有问题。


下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。
如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。
（经过我个人分析，这个重排序可以是单线程之内的多个指令重排序，也可以是多个线程的指令之间执行的顺序是随机的。也就是线程不安全。）
1. 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。
准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、 循环等结构。
2. 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。 这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。
（也就是一个线程从时间上讲，是先碰到对于一个锁的unlock操作，但还没有执行完unlock，另一个线程也是同样从时间上讲，后碰到对同一个锁的lock操作，也是还没有执行到，
此时，该规则会保证一定是先unlock，后lock）
3. volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
4. 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。
5. 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束、
Thread.isAlive()的返回值等手段检测到线程已经终止执行。
6. 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过T
hread.interrupted()方法检测到是否有中断发生。也就是说，interrupt()打断线程的执行的时机，必须早于Thread.interrupted()执行的时机
7. 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。
8. 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。
