Java内存模型和CPU的缓存模型十分相似，所以先从内存的缓存模型讲起；

处理器、高速缓存、主存之间的关系（画图）。

缓存一致性问题。

解决缓存一致性问题，使用锁：
总线锁：
顾名思义，总线锁就是用来锁住总线的，我们可以通过上图来了解总线在这个场景中所处的位置。当一个CPU核执行一个线程去访问数据做操作的时候，
它会向总线上发送一个LOCK信号，此时其他的线程想要去请求主内存中的同一个共享变量的时候，就会被阻塞，这样该处理器核心就可以独享这个共享
内存。可以理解为，总线锁通过把内存和CPU之间的通信锁住，把并行化的操作变成了串行，这会导致很严重的性能问题，这与我们需要多核多线程并行
操作来提高程序的效率的目的大相径庭。所以，随着技术的发展，就出现了缓存锁。

缓存锁：
简单的说，如果某个内存区域数据，已经同时被一个以上的处理器核缓存，缓存锁就会通过缓存一致性机制来保证共享数据的可见性，当其他处理器核
回写已经被锁定的缓存行的数据时会导致该缓存行无效。就是说当某块CPU核对缓存中的数据进行操作了之后，就通知其他CPU放弃储存在它们内部的缓
存，进而从主内存中重新读取。


处理器上有一套完整的协议，来保证缓存的一致性，比较经典的应该就是MESI协议了，其实现方法是在CPU缓存中保存一个标记位，以此来标记四种状态。
另外，每个Core的Cache控制器不仅知道自己的读写操作，也监听其它Cache的读写操作，就是嗅探（snooping）协议（我个人猜测这个所谓的嗅探
机制应该是类似于观察者模式的设计）。

M：被修改的。处于这一状态的数据，只在本CPU核中有缓存数据，而其他核中没有。同时其状态相对于内存中的值来说，是已经被修改的，只是没有更新到内存中。
E：独占的。处于这一状态的数据，只有在本CPU中有缓存，且其数据没有修改，即与内存中一致。
S：共享的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致。
I：无效的。本CPU中的这份缓存已经无效。

MESI协状态迁移：（MESI.gif）
当前核状态为Invalid
    事件：Local Read
    行为：
        如果其它Cache没有这份数据，本Cache从内存中取数据，Cache line状态变成E
        如果其它Cache有这份数据，且状态为M，则将数据更新到内存，本Cache再从内存中取数据，2个Cache 的Cache line状态都变成S
        如果其它Cache有这份数据，且状态为S或者E，本Cache从内存中取数据，这些Cache 的Cache line状态都变成S
    事件：Local Write
    行为：
        先从内存中取出数据到本Cache中，然后在本Cache中修改，状态变成M
        如果其它Cache有这份数据，且状态为M，则要先将其他Cache中的数据写入到内存
        如果其它Cache有这份数据，且状态为S，则其它Cache的Cache line状态变成I
    事件：Remote Read
    行为：既然是Invalid，别的核的操作与它无关
    事件：Remote Write
    行为：既然是Invalid，别的核的操作与它无关
当前核状态为Exclusive
    事件：Local Read
    行为：从Cache中取数据，状态不变
    事件：Local Write
    行为：修改Cache中的数据，状态变成M
    事件：Remote Read
    行为：数据和其它核共用，状态变成了S
    事件：Remote Write
    行为：数据被修改，本Cache line不能再使用，状态变成I
当前核状态为Shared
    事件：Local Read
    行为：从Cache中取数据，状态不变
    事件：Local Write
    行为：修改Cache中的数据，状态变成M，其它核共享的Cache line状态变成I
    事件：Remote Read
    行为：状态不变
    事件：Remote Write
    行为：数据被修改，本Cache line不能再使用，状态变成I
当前核状态为Modified
    事件：Local Read
    行为：从Cache中取数据，状态不变
    事件：Local Write
    行为：修改Cache中的数据，状态不变
    事件：Remote Read
    行为：这行数据被写到内存中，使其它核能使用到最新的数据，状态变成S
    事件：Remote Write
    行为：这行数据被写到内存中，使其它核能使用到最新的数据，由于其它核会修改这行数据，状态变成I


注意，考虑这样一种情况：
1. 核1读取i，核1状态成为E
2. 核2读取i，核1、核2状态都成为S
3. 核1修改i，核1变为M，核2变为I
4. 核2修改i，核1变为I，核2变为M

CPU的读取会遵循几个原则（其实就是上面说的嗅探）
一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在读取操作执行之前把M其缓存行中的数据写回主存。
（按我个人通俗一点说理解就是，我把内存中这个拼图玩具（数据）复制一份拿来玩，但是我要时刻注意有没有人要玩这个玩具，如果有人要玩，那我就要告诉他，这拼图已经被我拼成这样子了，
你从这个进度开始拼吧。）

一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。

一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。

当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，
如其他CPU也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取。当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令
(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下性能开销是相对较大的。在写入完成后，修改其缓存状态为M。所以如果一个变量在某段时间
只被一个线程频繁地修改，那么使用其内部缓存就完全可以了，并不需要涉及到总线事务。如果内存一会被这个CPU独占，一会被那个CPU独占，这时才会不断产生RFO指令影响到并发性
能。这其实是跟CPU协调机制有关，如果在CPU间调度不合理，会形成RFO指令的开销比任务开销还要大，喧宾夺主，我们反而不能提高效率。顺带一句题外话，之前听过一句话，程序玩
到最后都是性能和安全的博弈，深以为然，身为一个选择困难的人啊，很伤。

====================================================================================================================================================================================
JMM：java内存模型

JMM原子操作：
read：从主内存读取数据
load：将主内存读取到的数据写入工作内存
use：从工作内存读取数据来计算
assgin：将计算好的值重新赋值到工作内存中
store：把工作内存中变量的值同步回主内存，以便随后的write操作使用
write：将store到主内存的变量值，赋值给主内存中的变量
lock：将主内存变量加锁，标识为线程独占状态
unlock：将主内存变量解锁，解锁后其他线程可以锁定该变量

volatile缓存可见性实现原理
底层实现主要是通过汇编lock前缀指令，它会锁定这块内存区域的缓存并回写到主内存，此操作被称为“缓存锁定”

Java程序汇编代码查看（记得将hsdis解压到jre/bin/server目录下，并且将该jre环境指定为当前idea项目的运行环境）
-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*App.f1


并发编程三大特性：
可见性
原子性
有序性

volatile只保证
    可见性
    有序性
synchronized保证
    可见性
    有序性
    原子性

有序性：Java内存模型的有序性在上面讲解volatile时也详细地讨论过了，Java程序中天然的有序性可以总结为一句话：
如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“
线程内表现为串行的语义“（Within-Thread As-If-Serial Semantics），后半句是指”指令重排序“现象和”工作
内存与主内存同步延迟“现象。

指令重拍，单线程之内，结果不变

特别关键的点：
volatile之所以不保证原子性，是因为volatile修饰的变量在不同的线程的工作内存中也存在不一致的情况。并不是任何一个线程修改了volatile变量，其他线程就能立刻感知
只有其他线程要从工作内存中使用变量的那一刻，才会发现工作内存的状态是I(invalid)，才会去主存中获取变量的值。
比如：
线程1                                         线程2
读取i=1                                       读取i=1
i++; // i=2                                   i++;    // i=2
此时没有刷新工作内存(因为此时没有涉及到读取)         存储i=2到主存
存储2到主存

所以，关于volatile才有了以下的使用准则
1. 运算结果并不依赖于变量当前的值，或者能够确保只有单一的线程修改变量的值，而其他的线程只是读取变量的值。
2. 变量不需要与其他的状态变量共同参与不变约束。

补充：JMM内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许虚拟机选择把这些操作实现为
具有原子性的操作，而且还是“强烈建议”虚拟机这样实现。在实际开发中，目前各种平台下的商用虚拟机几乎都选择把64位
数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile


先行发生原则（happen-before原则，针对的就是指令重排的机制）

如果Java内存模型中，线程之间的所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操作将会变得很烦琐，但是我们
在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个“先行发生（happens-before）”的原则，这个
原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地解决并发
环境下两个操作之间是否可能存在冲突的所有问题。


下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。
如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。
（经过我个人分析，这个重排序可以是单线程之内的多个指令重排序，也可以是多个线程的指令之间执行的顺序是随机的。也就是线程不安全。）
1. 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。
准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、 循环等结构。
2. 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。 这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。
（也就是一个线程从时间上讲，是先碰到对于一个锁的unlock操作，但还没有执行完unlock，另一个线程也是同样从时间上讲，后碰到对同一个锁的lock操作，也是还没有执行到，
此时，该规则会保证一定是先unlock，后lock）
3. volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
4. 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。
5. 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束、
Thread.isAlive()的返回值等手段检测到线程已经终止执行。
6. 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过T
hread.interrupted()方法检测到是否有中断发生。也就是说，interrupt()打断线程的执行的时机，必须早于Thread.interrupted()执行的时机
7. 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。
8. 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。